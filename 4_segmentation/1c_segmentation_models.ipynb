{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on https://github.com/qubvel/segmentation_models.pytorch/blob/master/examples/cars%20segmentation%20(camvid).ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation Models\n",
    "\n",
    "[Segmentation Models for PyTorch](https://github.com/qubvel/segmentation_models.pytorch) (SMP) is a Python library with which you can easily build neural networks for **semantic image segmentation**. You can install it with \n",
    "\n",
    "```bash\n",
    "pip install segmentation-models-pytorch\n",
    "```\n",
    "\n",
    "and import it in your code base with\n",
    "\n",
    "```python\n",
    "import segmentation_models_pytorch as smp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "The first step is to set up the semantic segmentation model itself. The library gives you a lot of choices.\n",
    "\n",
    "For example, you can choose:\n",
    "\n",
    "* The **model architecture**: UNet, FPN,...\n",
    "* The **encoder**: ResNet, Inception, VGG, MobileNet,...\n",
    "* The pretrained encoder **weights** to use: ImageNet plus some other large dataset, depending on the chosen encoder. If `None`, the weights will be randomly initialized.\n",
    "* The number of **output channels** (= number of classes)\n",
    "* **Activation function**: activation to apply to the output of the final convolutional layer\n",
    "* Some other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "ENCODER = 'resnet50'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['car']\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
    "\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES), \n",
    "    activation=ACTIVATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define train and test transforms\n",
    "\n",
    "To avoid overfitting, we apply some basic data augmentation transforms.\n",
    "\n",
    "Note that the concatenations in the decoder part are only possible when the input size is **divisible by 32** (and larger than 64 pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0,\n",
    "                       shift_limit=0.1, p=1, border_mode=0),\n",
    "    A.PadIfNeeded(min_height=320, min_width=320,\n",
    "                  always_apply=True, border_mode=0),\n",
    "    A.RandomCrop(height=320, width=320, always_apply=True),\n",
    "])\n",
    "\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    # Add paddings to make image shape divisible by 32\n",
    "    A.PadIfNeeded(\n",
    "        min_height=None,\n",
    "        min_width=None,\n",
    "        pad_height_divisor=32,\n",
    "        pad_width_divisor=32,\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define preprocessing transform\n",
    "\n",
    "Apart from the data augmentations, we also apply a preprocessing step to transform the image into an input that is compatible with the model, i.e. the same normalization as the pretrained weights and the correct data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "preprocess_transform = A.Compose([\n",
    "    A.Lambda(image=preprocessing_fn),\n",
    "    A.Lambda(image=to_tensor, mask=to_tensor),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lib.camvid import CamVid\n",
    "\n",
    "DATA_DIR = './data/CamVid/'\n",
    "\n",
    "train_dataset = CamVid(\n",
    "    DATA_DIR, \n",
    "    'train', \n",
    "    augmentation=train_transform, \n",
    "    preprocessing=preprocess_transform,\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "valid_dataset = CamVid(\n",
    "    DATA_DIR,\n",
    "    'val',\n",
    "    augmentation=test_transform,\n",
    "    preprocessing=preprocess_transform,\n",
    "    classes=CLASSES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8,\n",
    "                          shuffle=True, num_workers=12)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1,\n",
    "                          shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss, optimizer and metrics\n",
    "\n",
    "### Soft Dice loss\n",
    "\n",
    "We use the **soft Dice loss** as a loss function. This is a \"soft\" loss-variant of the Dice score (or Dice similarity coefficient, DSC):\n",
    "\n",
    "$$\n",
    "\\text{DSC} = \\frac{2|Y_{\\text{true}}\\cap Y_{\\text{pred}}|}{|Y_{\\text{true}}| + |Y_{\\text{pred}}|}\n",
    "$$\n",
    "\n",
    "or, in other words,\n",
    "\n",
    "$$\n",
    "\\text{DSC} = \\frac{2\\cdot\\text{TP}}{2\\text{TP}+\\text{FP}+\\text{FN}}\n",
    "$$\n",
    "\n",
    "(Note that this is exactly the same as the F1 score, which is the harmonic mean between precision and recall.)\n",
    "\n",
    "As you can see, we need positive (car) and negative (no car) predictions for each pixel to compute the regular Dice similarity coefficient. However, this does not take into account how confident the network is of each prediction. The *soft* Dice score, on the other hand, is calculated as\n",
    "\n",
    "$$\n",
    "\\text{DSC}_{\\text{soft}} = \\frac{2\\cdot Y_{\\text{true}} \\odot \\tilde{Y}_{\\text{pred}}}{Y_{\\text{true}} + \\tilde{Y}_{\\text{pred}}}\n",
    "$$\n",
    "\n",
    "with $\\tilde{Y}_{\\text{pred}}$ containing the confidence scores and $\\odot$ the element-wise multiplication of both matrices (or tensors, in general). The **soft Dice loss** is then defined as one minus the soft Dices score:\n",
    "\n",
    "$$\n",
    "\\text{Soft Dice loss} = 1 - \\text{DSC}_{\\text{soft}}\n",
    "$$\n",
    "\n",
    "\n",
    "See [here](https://github.com/qubvel/segmentation_models.pytorch/blob/740dab561ccf54a9ae4bb5bda3b8b18df3790025/segmentation_models_pytorch/losses/_functional.py#L172) and [here](https://github.com/qubvel/segmentation_models.pytorch/blob/740dab561ccf54a9ae4bb5bda3b8b18df3790025/segmentation_models_pytorch/losses/dice.py#L111) for the implementation in `smp`.\n",
    "\n",
    "### Jaccard index\n",
    "\n",
    "To evaluate our result, we use the **Jaccard index**, which is actually another name for the Intersection over Union (IoU):\n",
    "\n",
    "$$\n",
    "\\text{Jaccard index} = \\frac{|Y_{\\text{true}}\\cap Y_{\\text{pred}}|}{|Y_{\\text{true}}\\cup Y_{\\text{pred}}|}\n",
    "$$\n",
    "\n",
    "Unlike the soft Dice loss, we pass in a threshold that will turn the model's confidence scores into binary classifications (car/no car)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Dice/F1 score - https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
    "# IoU/Jaccard score - https://en.wikipedia.org/wiki/Jaccard_index\n",
    "\n",
    "loss = smp.utils.losses.DiceLoss()\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.0001),\n",
    "])\n",
    "\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create epoch runners\n",
    "\n",
    "This is a simple loop that iterates over the corresponding dataloader's batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=device,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "\n",
    "max_score = 0\n",
    "\n",
    "for i in range(0, num_epochs):\n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "\n",
    "    if max_score < valid_logs['iou_score']:\n",
    "        # Save model when it is better than the previous best\n",
    "        max_score = valid_logs['iou_score']\n",
    "        torch.save(model, './best_model.pth')\n",
    "        print('Model saved!')\n",
    "        \n",
    "    if i == 25:\n",
    "        optimizer.param_groups[0]['lr'] = 1e-5\n",
    "        print('Decrease decoder learning rate to 1e-5!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test best saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best saved checkpoint\n",
    "best_model = torch.load('./best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CamVid(\n",
    "    DATA_DIR, 'test',\n",
    "    augmentation=test_transform,\n",
    "    preprocessing=preprocess_transform,\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch = smp.utils.train.ValidEpoch(\n",
    "    model=best_model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "logs = test_epoch.run(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.plot import visualize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset without transformations for image visualization\n",
    "test_dataset_vis = CamVid(\n",
    "    DATA_DIR, 'test',\n",
    "    classes=['car'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    n = np.random.choice(len(test_dataset))\n",
    "    \n",
    "    image_vis = test_dataset_vis[n][0].astype('uint8')\n",
    "    image, gt_mask = test_dataset[n]\n",
    "    \n",
    "    gt_mask = gt_mask.squeeze()\n",
    "    \n",
    "    x_tensor = torch.from_numpy(image).to(device).unsqueeze(0)\n",
    "    pr_mask = best_model.predict(x_tensor)\n",
    "    pr_mask = (pr_mask.squeeze().cpu().numpy().round())\n",
    "        \n",
    "    visualize(\n",
    "        image=image_vis, \n",
    "        ground_truth_mask=gt_mask, \n",
    "        predicted_mask=pr_mask\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
