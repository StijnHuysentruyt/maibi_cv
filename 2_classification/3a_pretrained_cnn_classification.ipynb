{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "141a459c",
   "metadata": {},
   "source": [
    "# Pretrained CNN classification\n",
    "\n",
    "We use a pretrained CNN to classify images into ImageNet classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a76625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from lib.imagenet_classes import idx2label\n",
    "from lib.plots import plot_transformed_val_input\n",
    "from lib.cnn_classifiers import val_transform, get_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99130e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19d43670d4f475b98808968a5da31a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='model_name', options=('alexnet', 'vgg19', 'inception_v3', 'resnet5â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "\n",
    "soda_imgs = sorted(\n",
    "    str(img_path)\n",
    "    for img_path in Path('data/sodas/query/').glob('**/*.jpg')\n",
    ")\n",
    "\n",
    "@interact(\n",
    "    model_name=['alexnet', 'vgg19', 'inception_v3', 'resnet50'],\n",
    "    img_path=soda_imgs,\n",
    "    pretrained=True\n",
    ")\n",
    "def classify_img(model_name, img_path, pretrained=True):\n",
    "    model = get_cnn(model_name, pretrained)\n",
    "    model.eval()\n",
    "\n",
    "    im = Image.open(img_path)\n",
    "    print('Original shape:', np.array(im).shape)\n",
    "\n",
    "    # Transform the image\n",
    "    x = val_transform(im)\n",
    "    print('Shape after transform:', x.shape)\n",
    "\n",
    "    plot_transformed_val_input(im)\n",
    "\n",
    "    # Add batch dimension\n",
    "    x = x.unsqueeze(0)\n",
    "    print('Input shape:', x.shape)\n",
    "\n",
    "    # Pass through model\n",
    "    with torch.no_grad():\n",
    "        y = model(x)\n",
    "    print('Output shape:', y.shape)\n",
    "\n",
    "    # Remove batch dimension\n",
    "    y = y.squeeze()\n",
    "    print('Squeezed output shape:', y.shape)\n",
    "\n",
    "    # Softmax to get procentual scores\n",
    "    y = torch.nn.functional.softmax(y, dim=0)\n",
    "\n",
    "    # Get top 10 matches\n",
    "    print()\n",
    "    top_10_idxs = y.argsort(descending=True)[:10].numpy()\n",
    "    top_10 = [f'{idx2label[idx]} ({y[idx]*100:.1f}%)'\n",
    "              for idx in top_10_idxs]\n",
    "    \n",
    "    print('Top 10 matches:\\n', '\\n'.join([f'\\t{i + 1}) {label}' for i, label in enumerate(top_10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f1af8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
