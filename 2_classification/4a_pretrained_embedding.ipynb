{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d214b1e9",
   "metadata": {},
   "source": [
    "# Pretrained embedding\n",
    "\n",
    "By cutting off the last layer of the network, we can obtain a feature vector (also *embedding*, *descriptor* or *high-level representation*) of the input image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba2532b",
   "metadata": {},
   "source": [
    "## Compose a set of gallery and query images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58dd3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.soda_dataset import get_gallery_and_queries\n",
    "\n",
    "gallery, queries, gallery_labels, query_labels = get_gallery_and_queries()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3228f4b1",
   "metadata": {},
   "source": [
    "## Calculate similarity matrix using query and gallery embeddings\n",
    "\n",
    "We compute the [cosine similarity score](https://en.wikipedia.org/wiki/Cosine_similarity) between each gallery embedding and each query embedding, which is the **cosine of the angle between the embeddings**. When embeddings are **the same**, the angle between them will be zero and the cosine of the angle will be **1**. **Perpendicular** embeddings have a cosine similarity of **0** and **opposite** embeddings have a cosine similarity of **-1**.\n",
    "\n",
    "When the embeddings are already normalized, computing the cosine similarity boils down to a **matrix multiplication** of the matrix formed by the gallery embeddings and the matrix formed by the query embeddings.\n",
    "\n",
    "Note that for normalized embeddings, sorting pairs of embeddings from smallest to largest distance will yield the same ranking as sorting them for largest to smallest cosine similarity score. However, computing the distance requires more computations and can easily be **five times slower**, as we can see below. Hence, we prefer to use cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82e35ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from lib.metric_learning import match_pretrained_embeddings\n",
    "\n",
    "sim_mat = match_pretrained_embeddings(gallery, queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e886760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.plots import plot_sim_mat\n",
    "\n",
    "plot_sim_mat(sim_mat, gallery_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540611aa",
   "metadata": {},
   "source": [
    "# Evaluate the results\n",
    "\n",
    "See [2_evaluation_metrics.ipynb](./2_evaluation_metrics.ipynb) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c1006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.plots import plot_pr_curves\n",
    "\n",
    "plot_pr_curves(sim_mat, gallery_labels, query_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd3d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.plots import plot_aps\n",
    "\n",
    "plot_aps(sim_mat, gallery_labels, query_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f658a7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
